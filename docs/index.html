<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.8/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-sRIl4kxILFvY47J16cr9ZwB07vP4J8+LH7qKQnuqkuIAvNWLzeN8tE5YBujZqJLB" crossorigin="anonymous">
    <style>
    :root { --nav-h: 56px; }
        .comment {
            font-style: italic;
            color: #11f0f8;
        }

        body {
            background-color: #1a1a1a;  /* 어두운 회색 */
            color: #e0e0e0;            /* 밝은 회색 텍스트 */
        }

        summary { cursor: default; }
        /* 부트스트랩 네비바 컬러 변수로 다크톤 통일 */

        .navbar {
            --bs-navbar-bg: #2c2c2c;
            --bs-navbar-color: #cbd5e1;
            --bs-navbar-hover-color: #ffffff;
            --bs-navbar-active-color: #ffffff;
            --bs-navbar-brand-color: #ffffff;
            --bs-navbar-brand-hover-color: #ffffff;
            --bs-navbar-toggler-border-color: #3a3f45;
        }
        .navbar .dropdown-menu {
            background: #2b2f36;
            border-color: #3a3f45;
        }
        .navbar .dropdown-item { color: #cbd5e1; }
        .navbar .dropdown-item:hover { background: #3a3f45; color: #ffffff; }
        /* 제목들도 밝게 */
        h1, h2 {
            color: #ffffff;
        }

        h3, h4, h5, h6 {
            color: #d0d0d0;
            margin-left: 20px;
        }

        /* 링크 색상 조정 */
        a {
            color: #4dabf7;
        }

          .code-container {
      position: relative;
      background: #33373c;
      border-radius: 6px;
      padding: 16px;
      margin: 10px 0;
        }

        .copy_button {
            position: absolute;
            top: 8px;
            right: 8px;
            background: #fbfbfb;
            color: rgb(10, 10, 10);
            border: none;
            padding: 6px 10px;
            border-radius: 4px;
            font-size: 11px;
            cursor: pointer;
            transition: background-color 0.2s;
        }
            
        .copy_button:hover {
            background: #ebeae9;
        }

        .copy_button:active {
            background: #eeefee;
            transform: scale(0.98);
        }

        pre {
            margin: 0;
            overflow-x: auto;
        }

        code {
            font-family: 'Consolas', 'Monaco', monospace;
            font-size: 13px;
            line-height: 1.4;
            color: #fbfffb;
            white-space: pre-wrap;
        }

        var {
            color: rgb(138, 111, 246);
            font-family: 'Consolas', 'Monaco', monospace;
            font-size: 13px;
            line-height: 1.4;

        }

    /* 레이아웃 */
    html { scroll-behavior: smooth; }
    .layout { display: flex; gap: 16px; }
    .sidebar {
        width: 260px;
        flex: 0 0 260px;
        height: calc(100vh - var(--nav-h));
        position: sticky;
        top: var(--nav-h);
        overflow: auto;
        background: #23262a;
        border-right: 1px solid #2f3338;
        padding: 16px 12px;
    }
    .sidebar-title {
        color: #fff;
        font-weight: 700;
        margin: 4px 8px 10px;
        font-size: 16px;
    }
    .sidebar ul { list-style: none; padding-left: 0; margin: 0; }
    .sidebar li { margin: 4px 0; }
    .sidebar a {
        display: block;
        padding: 6px 10px;
        color: #cbd5e1;
        text-decoration: none;
        border-radius: 6px;
        font-size: 13px;
    }
    .sidebar a:hover { background: #2b2f36; color: #fff; }
    .sidebar a.active { background: #3a3f45; color: #fff; }

    .sidebar .sub { margin-left: 10px; border-left: 1px dashed #3a3f45; padding-left: 10px; }
    .content { flex: 1; min-width: 0; padding: 0 8px 80px; }
    /* 스티키 네비바 사용 시 앵커가 헤더에 가려지지 않도록 여백 (네비바 높이 기반) */
    .docs-section h3, .docs-section details { scroll-margin-top: calc(var(--nav-h) + 16px); }

    @media (max-width: 900px) {
    .layout { flex-direction: column; }
    .sidebar { position: relative; height: auto; width: 100%; top: 0; }
    }
    </style>
    <title>AI Multi-Agent Toolkit - Documentation</title>
    <script>
        function copy_button(id) {
            const code = document.getElementById(id)
            const codeText = code.textContent
            navigator.clipboard.writeText(codeText).then(() => {
                alert('Code copied to clipboard!')
            }).catch(err => {
                console.error('Failed to copy text: ', err)
            })
        }

        // --- 사이드바 자동 생성 ---
        function slugify(text) {
            return String(text || '')
                .toLowerCase()
                .replace(/[^\w가-힣\s-]/g, '')
                .trim()
                .replace(/\s+/g, '-');
        }

        function buildSidebar() {
            const container = document.querySelector('.docs-section');
            if (!container) return;

            // H3와 details를 섹션 구조로 매핑 (H3 밑의 details를 자식으로)
            const blocks = Array.from(container.children);
            const sections = [];
            let current = null;

            for (const el of blocks) {
                if (el.tagName === 'H3') {
                    const title = el.textContent.trim();
                    if (!el.id) el.id = slugify(title);
                    current = { h3: el, items: [] };
                    sections.push(current);
                } else if (el.tagName === 'DETAILS' && current) {
                    const summary = el.querySelector('summary');
                    const text = summary ? summary.textContent.trim() : 'details';
                    if (!el.id) el.id = slugify((current.h3.textContent || '') + '-' + text);
                    current.items.push({ el, text });
                }
            }

            // 사이드바 DOM 생성
            const nav = document.getElementById('sidebar-nav');
            if (!nav) return;
            nav.innerHTML = '';

            for (const sec of sections) {
                const li = document.createElement('li');
                const a = document.createElement('a');
                a.href = `#${sec.h3.id}`;
                a.textContent = sec.h3.textContent.trim();
                li.appendChild(a);

                if (sec.items.length) {
                    const ul = document.createElement('ul');
                    ul.className = 'sub';
                    for (const item of sec.items) {
                        const sli = document.createElement('li');
                        const sa = document.createElement('a');
                        sa.href = `#${item.el.id}`;
                        sa.textContent = item.text;
                        // 서브항목 클릭 시 details 열기
                        sa.addEventListener('click', () => { item.el.open = true; }, false);
                        sli.appendChild(sa);
                        ul.appendChild(sli);
                    }
                    li.appendChild(ul);
                }

                nav.appendChild(li);
            }
        }

        function setupActiveHighlight() {
            const links = Array.from(document.querySelectorAll('.sidebar a'));
            const map = new Map(links.map(a => [a.getAttribute('href'), a]));

            const targets = Array.from(document.querySelectorAll('.docs-section h3, .docs-section details'));
            const obs = new IntersectionObserver((entries) => {
                entries.forEach(e => {
                    if (e.isIntersecting) {
                        const id = '#' + e.target.id;
                        links.forEach(l => l.classList.remove('active'));
                        const link = map.get(id);
                        if (link) link.classList.add('active');
                    }
                });
            }, { rootMargin: '0px 0px -70% 0px', threshold: 0.1 });

            targets.forEach(t => t.id && obs.observe(t));
        }

        document.addEventListener('DOMContentLoaded', () => {
            buildSidebar();
            setupActiveHighlight();
            // 모두 펼치기
            document.querySelectorAll('.docs-section details').forEach(d => { d.open = true; });
        });
    </script>
</head>
<body>
    <nav class="navbar navbar-expand-lg sticky-top" data-bs-theme="dark">
  <div class="container-fluid">
    <a class="navbar-brand" href="#">AI Multi-Agent Toolkit</a>
    </div>
  </div>
</nav>
    <!-- 레이아웃 래퍼 추가 -->
    <div class="layout">
        <nav class="sidebar">
            <div class="sidebar-title">AI Toolkit</div>
            <ul id="sidebar-nav"></ul>
        </nav>

        <main class="content">
            <!-- 기존 문서 컨텐츠 래핑 -->
            <div class="docs-section"> 
    <h2>현재까지 구현된 기능</h2>
    <ul>
        <li>LLM 에이전트 생성 및 응답 받기 (ollama, openai, genai(gemini) 지원)</li>
        <li>Discord로 메시지 보내기 (메시지 청크 분할 및 겹침 지원)</li>
        <li>음성 파일을 텍스트로 변환하기 (whisper 사용)</li>
        <li>텍스트 청크 분할 및 겹침 지원</li>
        <li>2025/09/17 에이전트 메모리 기능 구현</li>
    </ul>
    <p>추가 기능은 추후 업데이트 예정입니다.</p>
    <h2>사용법</h2>
    <h3>1. LLM 에이전트</h3>
        <details>
            <summary>llm에이전트 생성하기</summary>
            <p>다음과 같이 에이전트를 생성하세요.</p>
                <div class = "code-container">
                    <button class = "copy_button" onclick = "copy_button('copy1')">Copy</button>
                    <pre><code id = "copy1">
        <var>model_name</var> = 'gemma:12b' <span class="comment">#사용할 모델명을 입력하세요</span>
        <var>system_prompt</var> = '당신은 유능한 비서입니다. 이용자에게 도움이 되는 답변을 제공합니다.'
        <var>user_prompt</var> = '프랑스의 수도는 어디인가요?'
        <var>provider</var> = 'ollama'  <span class="comment">#현재 사용가능한 provier는 "ollama", "openai","genai(gemini)"입니다</span>

        <var>agent</var> = LLM_Agent(model_name, provider, api_key=None)

        <var>response</var> = agent.generate_response(system_prompt, user_prompt, task=None)
        </var>print(response)</var>
            </code></pre>
            <p>위 코드에서 <code>model_name</code>은 사용할 모델의 이름을 지정합니다. <code>system_prompt</code>는 모델에게 주어지는 시스템 메시지이므로 역할 및 페르소나를 지정하세요. <code>user_prompt</code>는 llm에게 질문 및 작업을 요청하세요. <code>provider</code>는 사용할 LLM 제공자를 지정합니다.</p>
            <p> <code>task</code>의 기본값은 None이고 필요시 추가 하세요.</p>
            <p><code>api_key</code>의 기본값을 None이므로, ollama를 사용할 경우 API 키가 필요하지 않습니다.</p>
                </div>
        </details>
        <details>
            <summary>멀티 에이전트 활용하기</summary>
            <p>멀티 에이전트를 활용하려면 다음과 같이 하세요.</p>
            <p>여러개의 LLM 에이전트를 구성하세요. 순차적으로 에이전트를 호출하고, 앞의 에이전트의 응답을 다음 에이전트의 프롬프트에 포함시킵니다.</p>
                <div class = "code-container">
                    <button class = "copy_button" onclick = "copy_button('copy1-1')">Copy</button>
                    <pre><code id = "copy1-1">
        from module.llm_agent import LLM_Agent

        <var>system_prompt</var> = "You are a helpful assistant."
        <var>agent1_user_prompt</var> = "리눅스에 대해서 설명해주세요."
        <var>agent2_user_prompt</var> = "앞선 답변을 읽고 내용을 보충해 주세요"
        <span class="comment">#복수의 에이전트의 프롬프트를 정의합니다.</span>
        </var>multi_agent</var> = LLM_Agent(model_name="gemma3n", provider="ollama")
        <var>agent1</var> = multi_agent.generate_response(system_prompt, agent1_user_prompt, task=None)
        <var>agent2</var> = multi_agent.generate_response(system_prompt, agent2_user_prompt, task=None, multi_agent_response=agent1)<span class="comment">#agent1의 답변을 이어 받아, agent2의 프롬프트에 포함시킵니다.</span>
        print("Agent 1 Response:", agent1)
        print("Agent 2 Response:", agent2)
            </code></pre>
            <p>위 코드에서 <code>multi_agent_response</code> 매개변수를 사용하여 이전 에이전트의 응답을 다음 에이전트에게 전달합니다. 작업을 분할하고 각 에이전트에 맞게 프롬프트를 조정할 수 있습니다.</p>
            <p>첫번째 에이전트의 작업을 두번째 에이전트에 전달하여, 각 에이전트가 <var>task</var>를 심화하여 수행할 수 있도록 설정하세요.</p>
                </div>
        </details>
        <details>
            <summary>모든 에이전트의 응답 통합하기</summary>
            <p>에이전트에게 작업을 각각 할당하고 통합하여 최종 응답을 생성합니다.</p>
                <div class = "code-container">
                    <button class = "copy_button" onclick = "copy_button('copy1-2')">Copy</button>
                    <pre><code id = "copy1-2">
        from module.llm_agent import LLM_Agent
        
        <span class="comment">#각 에이전트의 시스템 프롬프트, 사용자 프롬프트, 작업을 정의합니다.</span>
        <var>multi_agent_tasks</var> = {
            "Agent 1": "도시에서 발생하는 환경 문제(대기, 수질, 쓰레기 등)를 정리하고, 가장 시급한 과제를 제시한다.",
            "Agent 2": "친환경 교통수단(대중교통, 자전거, 전기차 등)을 기반으로 지속 가능한 교통 인프라 계획을 제안한다.",
            "Agent 3": "재생에너지(태양광, 풍력, 스마트 그리드 등)를 활용하여 효율적인 에너지 공급 방안을 설계한다.",
            "Agent 4": "도시 공간 구조(공원, 주거, 상업지구 배치 등)를 최적화한다."
        }
        <var>multi_agent_system_prompts</var> = {
            "Agent 1": "당신은 환경 전문가입니다. 도시의 환경 문제를 분석하고, 가장 시급한 문제를 제시하세요.",
            "Agent 2": "당신은 교통 전문가입니다. 지속 가능한 교통 인프라 계획을 제안하세요.",
            "Agent 3": "당신은 에너지 전문가입니다. 재생에너지를 활용한 에너지 공급 방안을 설계하세요.",
            "Agent 4": "당신은 도시 계획 전문가입니다. 도시 공간 구조를 최적화하는 방안을 제시하세요."
        }
        <var>user_prompts</var> ={
            "Agent 1": "도시에서 발생하는 환경 문제를 분석하고, 가장 시급한 문제를 제시하세요.",
            "Agent 2": "지속 가능한 교통 인프라 계획을 제안하세요.",
            "Agent 3": "재생에너지를 활용한 에너지 공급 방안을 설계하세요.",
            "Agent 4": "도시 공간 구조를 최적화하는 방안을 제시하세요."
        }


        <var>order</var> = ["Agent 1", "Agent 2", "Agent 3", "Agent 4"]

        <var>multi_agent</var> = LLM_Agent(model_name="gemini-2.5-flash", provider="genai", api_key="your_api_key") <span class="comment">#여러 에이전트를 생성합니다.</span>

        <var>agent_responses</var> = {
            name: multi_agent.generate_response(multi_agent_system_prompts[name], user_prompts[name], multi_agent_tasks[name])
            for name in order
        }
        <var>response_list</var> = [agent_responses[name] for name in order] <span class="comment">#각 에이전트의 응답을 순서대로 리스트에 저장합니다.</span>

        <var>multi_agent_responses</var> = multi_agent.aggregate_responses(
            "당신은 도시 계획 전문가입니다. 지속 가능한 도시 설계 방안을 제시하세요.",
            "다음은 여러 전문가의 의견입니다. 이를 바탕으로 최종 요약 및 통합된 지속 가능한 도시 설계 방안을 제시하세요.",
            "최종 요약 및 통합된 지속 가능한 도시 설계 방안을 제시한다.",
            response_list
        ) <span class="comment">#모든 에이전트의 응답을 통합하여 최종 응답을 생성합니다.</span>

        print("Agent 1 Response:", agent_responses["Agent 1"])
        print("Agent 2 Response:", agent_responses["Agent 2"])
        print("Agent 3 Response:", agent_responses["Agent 3"])
        print("Agent 4 Response:", agent_responses["Agent 4"])
        print("Multi-Agent Responses:", multi_agent_responses)
            </code></pre>
            <p>위 코드에서 각 에이전트는 특정 작업을 수행하고, 그 응답은 최종 통합 응답을 생성하는 데 사용됩니다. 에이전트 별로 각각의 작업을 할당하고, 하나로 통합한 답을 생성합니다.</p>
        </details>
        <details>
            <summary>LLM에이전트에 기억력 붙이기</summary>
            <p>LLM 에이전트에 기억력을 추가하여 이전 대화 내용을 기억하고 활용할 수 있습니다.</p>
            <div class = "code-container">
                <button class = "copy_button" onclick = "copy_button('copy1-3')">Copy</button>
            <pre><code id="copy1-3">
        import dotenv
        import os
        dotenv.load_dotenv()

        # LLM_Agent 인스턴스 생성
        llm = LLM_Agent(model_name="gemini-2.5-flash", provider="genai", api_key=os.getenv("GENAI_API_KEY"), max_history=10) <span class="comment">#max_history = 기억할 대화 수</span>
        # 대화 루프 예시

        while True:
            <var>user_input</var> = input("You: ")
            <var>response</var> = llm.generate_response(system_prompt="You are a helpful assistant.", user_message=user_input, memory=True) <span class="comment">#memory=True로 설정하여 기억력 활성화</span>
            print("Assistant:", response)

            if user_input.lower() in ['exit', 'quit']:
                break

            </code></pre>
            <p>간단한 대화 예시입니다. max_history=10으로 설정하여 10개의 이전 대화를 기억합니다.</p>
            <p>memory를 활성화 시켜 이전 대화 내용을 활용할 수 있습니다. DB = sqlite3로 제작되었습니다.</p>
        </details>
    <h3>2. Discord로 메세지 보내기</h3>
        <details>
            <summary>LLM응답 결과를 Discord로 전송하기</summary>
            <p>다음과 같이 Discord로 메시지를 전송할 수 있습니다.</p>
            <div class="code-container">
                <button class="copy_button" onclick="copy_button('copy2')">Copy</button>
                <pre><code id="copy2">
        from module.discord import Send_to_discord
        from module.llm_agent import LLM_Agent
                    
        <var>model_name</var> = 'gemma3:12b' #사용할 모델명을 입력하세요
        <var>system_prompt</var> = '당신은 유능한 비서입니다. 이용자에게 도움이 되는 답변을 제공합니다.'
        <var>user_prompt</var> = '프랑스의 수도는 어디인가요?'
        <var>provider</var> = 'ollama'  <span class="comment">#현재 사용가능한 provier는 "ollama", "openai","genai(gemini)"입니다</span>

        <var>agent</var> = LLM_Agent(model_name, provider, api_key=None)
        <var>response</var> = agent.generate_response(system_prompt, user_prompt, task=None)

        <var>discord</var> = Send_to_discord(base_url="your_discord_webhook_url") <span class="comment">#청크 사이즈 및 겹침 크기 설정</span>
        discord.send_message(response)
                </code></pre>
            </div>
        </details>

        <details>
            <summary>메시지 청크 분할 및 겹침 설정하기</summary>
            <p>Discord로 메시지를 보낼 때, 메시지가 너무 길 경우 청크로 나누어 전송할 수 있습니다. 다음과 같이 설정할 수 있습니다.</p>
            <div class="code-container">
                <button class="copy_button" onclick="copy_button('copy2-1')">Copy</button>
                <pre><code id="copy2-1">
        from module.discord import Send_to_discord
        from module.llm_agent import LLM_Agent
        
        <span class="comment">#각 에이전트의 시스템 프롬프트, 사용자 프롬프트, 작업을 정의합니다.</span>
        <var>multi_agent_tasks</var> = {
            "Agent 1": "도시에서 발생하는 환경 문제(대기, 수질, 쓰레기 등)를 정리하고, 가장 시급한 과제를 제시한다.",
            "Agent 2": "친환경 교통수단(대중교통, 자전거, 전기차 등)을 기반으로 지속 가능한 교통 인프라 계획을 제안한다.",
            "Agent 3": "재생에너지(태양광, 풍력, 스마트 그리드 등)를 활용하여 효율적인 에너지 공급 방안을 설계한다.",
            "Agent 4": "도시 공간 구조(공원, 주거, 상업지구 배치 등)를 최적화한다."
        }
        <var>multi_agent_system_prompts</var> = {
            "Agent 1": "당신은 환경 전문가입니다. 도시의 환경 문제를 분석하고, 가장 시급한 문제를 제시하세요.",
            "Agent 2": "당신은 교통 전문가입니다. 지속 가능한 교통 인프라 계획을 제안하세요.",
            "Agent 3": "당신은 에너지 전문가입니다. 재생에너지를 활용한 에너지 공급 방안을 설계하세요.",
            "Agent 4": "당신은 도시 계획 전문가입니다. 도시 공간 구조를 최적화하는 방안을 제시하세요."
        }
        <var>user_prompts</var> ={
            "Agent 1": "도시에서 발생하는 환경 문제를 분석하고, 가장 시급한 문제를 제시하세요.",
            "Agent 2": "지속 가능한 교통 인프라 계획을 제안하세요.",
            "Agent 3": "재생에너지를 활용한 에너지 공급 방안을 설계하세요.",
            "Agent 4": "도시 공간 구조를 최적화하는 방안을 제시하세요."
        }


        <var>order</var> = ["Agent 1", "Agent 2", "Agent 3", "Agent 4"]

        <var>multi_agent</var> = LLM_Agent(model_name="gemini-2.5-flash", provider="genai", api_key="your_api_key") <span class="comment">#여러 에이전트를 생성합니다.</span>

        <var>agent_responses</var> = {
            name: multi_agent.generate_response(multi_agent_system_prompts[name], user_prompts[name], multi_agent_tasks[name])
            for name in order
        }
        <var>response_list</var> = [agent_responses[name] for name in order] <span class="comment">#각 에이전트의 응답을 순서대로 리스트에 저장합니다.</span>

        <var>multi_agent_responses</var> = multi_agent.aggregate_responses(
            "당신은 도시 계획 전문가입니다. 지속 가능한 도시 설계 방안을 제시하세요.",
            "다음은 여러 전문가의 의견입니다. 이를 바탕으로 최종 요약 및 통합된 지속 가능한 도시 설계 방안을 제시하세요.",
            "최종 요약 및 통합된 지속 가능한 도시 설계 방안을 제시한다.",
            response_list
        ) <span class="comment">#모든 에이전트의 응답을 통합하여 최종 응답을 생성합니다.</span>

        print("Agent 1 Response:", agent_responses["Agent 1"])
        print("Agent 2 Response:", agent_responses["Agent 2"])
        print("Agent 3 Response:", agent_responses["Agent 3"])
        print("Agent 4 Response:", agent_responses["Agent 4"])
        print("Multi-Agent Responses:", multi_agent_responses)
        <var>discord</var> = Send_to_discord(base_url="your_discord_webhook_url", chunk_size=1900) <span class="comment">#청크 사이즈 및 겹침 크기 설정</span>
        discord.send_message(multi_agent_responses)
                </code></pre>
        <p>위 코드에서 <code>chunk_size</code> 매개변수를 사용하여 각 메시지 청크의 최대 길이를 설정할 수 있습니다. Discord의 메시지 길이 제한을 고려하여 적절한 크기로 설정하세요. <code>overlap</code> 매개변수는 청크 간의 겹침 크기를 설정합니다. 기본값은 0이며, 필요에 따라 조정할 수 있습니다.</p>
        <p>청크로 나누어진 메시지는 순차적으로 Discord 채널에 전송됩니다.</p>
            </div>
        </details>

    </div>
</main>
    </div>
    <!-- 부트스트랩 JS (토글/드롭다운 동작) -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.8/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>
